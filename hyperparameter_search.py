import itertools
import json
import pandas as pd
from pathlib import Path
from ultralytics import YOLO
import torch
import time
from datetime import datetime
import yaml

class HyperparameterSearchRecall:
    def __init__(self, 
                 dataset_paths: list,
                 target_class: int = 4,  # Clase de minerÃ­a ilegal
                 base_epochs: int = 250,
                 gpu_memory_gb: int = 24):
        
        self.dataset_paths = dataset_paths
        self.target_class = target_class
        self.base_epochs = base_epochs
        self.gpu_memory = gpu_memory_gb
        self.results = []
        
        # Directorio para guardar resultados
        self.output_dir = Path(f"hyperparameter_search_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        self.output_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ” BÃºsqueda de hiperparÃ¡metros iniciada")
        print(f"ğŸ¯ Objetivo: Maximizar recall de clase {target_class} (minerÃ­a ilegal)")
        print(f"ğŸ“Š Datasets: {len(dataset_paths)}")
        print(f"âš¡ GPU: {gpu_memory_gb}GB disponibles")
        print(f"ğŸ“ Resultados en: {self.output_dir}")

    def get_hyperparameter_combinations(self):
        """Define las combinaciones de hiperparÃ¡metros a evaluar"""
        
        # ğŸ¯ CONFIGURACIONES ESPECÃFICAS PARA MINERÃA ILEGAL
        # Basadas en tu problema especÃ­fico con 4000+ imÃ¡genes aumentadas
        
        mining_optimized_configs = [
            # Config 1: Ultra Recall - MÃ¡ximo recall para minerÃ­a
            #{
            #    'batch_size': 40, 'lr0': 0.02, 'lrf': 0.2, 'cos_lr': True,
            #    'weight_decay': 0.0005, 'dropout': 0.0, 'mosaic': 1.0, 
            #    'mixup': 0.15, 'imgsz': 640, 'model_size': 'yolo11m.pt',
            #    'name': 'ultra_recall'
            #},
            
            # Config 2: High Resolution - Para detalles finos
            #{
            #    'batch_size': 40, 'lr0': 0.015, 'lrf': 0.15, 'cos_lr': True,
            #    'weight_decay': 0.001, 'dropout': 0.1, 'mosaic': 0.9, 
            #    'mixup': 0.1, 'imgsz': 832, 'model_size': 'yolo11l.pt',
            #    'name': 'high_resolution'
            #},
            
            # Config 3: Balanced - Balance recall/precision
            #{
            #    'batch_size': 32, 'lr0': 0.01, 'lrf': 0.1, 'cos_lr': True,
            #    'weight_decay': 0.001, 'dropout': 0.05, 'mosaic': 0.85, 
            #    'mixup': 0.05, 'imgsz': 640, 'model_size': 'yolo11m.pt',
            #    'name': 'balanced'
            #},
            
            # Config 4: Conservative - Estable y confiable
            {
                'batch_size': 40, 'lr0': 0.005, 'lrf': 0.01, 'cos_lr': True,
                'weight_decay': 0.001, 'dropout': 0.1, 'mosaic': 0.8, 
                'mixup': 0.0, 'imgsz': 640, 'model_size': 'yolo11m.pt',
                'name': 'conservative'
            },
            
            # Config 5: Large Model Aggressive
            #{
            #    'batch_size': 32, 'lr0': 0.018, 'lrf': 0.18, 'cos_lr': False,
            #    'weight_decay': 0.002, 'dropout': 0.15, 'mosaic': 1.0, 
            #    'mixup': 0.1, 'imgsz': 640, 'model_size': 'yolo11l.pt',
            #    'name': 'large_aggressive'
            #},
            
            # Config 6: Tu configuraciÃ³n base mejorada
            #{
            #    'batch_size': 32, 'lr0': 0.01, 'lrf': 0.01, 'cos_lr': True,
            #    'weight_decay': 0.001, 'dropout': 0.1, 'mosaic': 0.8, 
            #    'mixup': 0.0, 'imgsz': 640, 'model_size': 'yolo11m.pt',
            #    'name': 'baseline_improved'
            #},
        ]
        
        # AÃ±adir variaciones de las mejores configuraciones
        #variations = []
        
        # Variaciones de la configuraciÃ³n ultra_recall
        #base_ultra = mining_optimized_configs[0].copy()
        
        # VariaciÃ³n con batch size mayor
        #var1 = base_ultra.copy()
        #var1.update({'batch_size': 48, 'name': 'ultra_recall_batch64'})
        #variations.append(var1)
        
        # VariaciÃ³n con learning rate mÃ¡s conservador
        #var2 = base_ultra.copy()
        #var2.update({'lr0': 0.015, 'name': 'ultra_recall_lr_conservative'})
        #variations.append(var2)
        
        # Variaciones de high_resolution
        #base_hires = mining_optimized_configs[1].copy()
        
        # High res con modelo medium (menos memoria)
        #var3 = base_hires.copy()
        #var3.update({'model_size': 'yolo11m.pt', 'batch_size': 40, 'name': 'high_res_medium'})
        #variations.append(var3)
        
        # Combinar todas las configuraciones
        all_configs = mining_optimized_configs 
        
        print(f"ğŸ§ª Configuraciones especÃ­ficas para minerÃ­a ilegal: {len(all_configs)}")
        print("ğŸ¯ Enfocadas en maximizar recall de clase 4")
        
        # Mostrar resumen de configuraciones
        for i, config in enumerate(all_configs):
            print(f"   {i+1}. {config['name']}: Batch={config['batch_size']}, "
                  f"LR={config['lr0']}, Img={config['imgsz']}, Model={config['model_size']}")
        
        return all_configs

    def estimate_memory_usage(self, batch_size, imgsz, model_size):
        """Estima el uso de memoria GPU"""
        base_memory = {
            'yolo11m.pt': 4.0,  # GB base
            'yolo11l.pt': 6.0   # GB base
        }
        
        # Factor por batch size e imagen
        memory_per_batch = batch_size * (imgsz / 640) ** 2 * 0.1
        total_memory = base_memory[model_size] + memory_per_batch
        
        return total_memory

    def train_single_config(self, config, dataset_path, run_id):
        """Entrena un modelo con una configuraciÃ³n especÃ­fica"""
        
        # Verificar memoria
        estimated_memory = self.estimate_memory_usage(
            config['batch_size'], config['imgsz'], config['model_size']
        )
        
        if estimated_memory > self.gpu_memory * 0.9:
            print(f"âš ï¸ Config {run_id}: Memoria estimada {estimated_memory:.1f}GB > {self.gpu_memory*0.9:.1f}GB")
            return None
        
        try:
            print(f"\nğŸš€ Entrenando configuraciÃ³n {run_id}:")
            print(f"   Dataset: {Path(dataset_path).name}")
            print(f"   Batch: {config['batch_size']}, LR: {config['lr0']}, Img: {config['imgsz']}")
            print(f"   Modelo: {config['model_size']}")
            
            # Limpiar cache GPU
            torch.cuda.empty_cache()
            
            # Crear modelo
            model = YOLO(config['model_size'])
            
            # Preparar argumentos de entrenamiento
            yaml_path = Path(dataset_path) / "dataset.yaml"
            config_name = config.get('name', f'config_{run_id}')
            run_name = f"hp_search_{run_id}_{config_name}_{Path(dataset_path).name}"
            
            # Argumentos especÃ­ficos para minerÃ­a ilegal
            train_args = {
                'data': str(yaml_path),
                'epochs': self.base_epochs,
                'imgsz': config['imgsz'],
                'batch': config['batch_size'],
                'lr0': config['lr0'],
                'lrf': config['lrf'],
                'cos_lr': config['cos_lr'],
                'weight_decay': config['weight_decay'],
                'dropout': config['dropout'],
                'mosaic': config['mosaic'],
                'mixup': config['mixup'],
                'patience': 5,  # Early stopping
                'save_period': -1,  # No guardar checkpoints intermedios
                'name': run_name,
                'exist_ok': True,
                'verbose': False,
                'workers': 8,
                
                # ğŸ¯ CONFIGURACIONES ESPECÃFICAS PARA RECALL DE MINERÃA
                'conf': 0.15,        # Confidence threshold bajo para detectar mÃ¡s
                'iou': 0.6,          # IoU threshold mÃ¡s permisivo  
                'max_det': 500,      # MÃ¡s detecciones por imagen
                'augment': True,     # Data augmentation durante entrenamiento
                'agnostic_nms': False, # Class-specific NMS
                'retina_masks': True,  # Better mask quality
                'overlap_mask': True,  # Handle overlapping masks
                'mask_ratio': 4,       # Mask downsampling ratio
                'boxes': True,         # Train bounding boxes
                
                # Optimizaciones de pÃ©rdida para clase desbalanceada
                'cls': 0.5,      # Classification loss weight
                'box': 7.5,      # Box loss weight (alto para buena localizaciÃ³n)
                'dfl': 1.5,      # Distribution focal loss weight
                'pose': 12.0,    # Pose loss weight
                'kobj': 1.0,     # Keypoint obj loss weight
                'label_smoothing': 0.0,  # Sin smoothing para preservar clase rara
                
                # Augmentaciones especÃ­ficas para minerÃ­a
                'hsv_h': 0.015,  # Hue augmentation (ligero)
                'hsv_s': 0.7,    # Saturation augmentation
                'hsv_v': 0.4,    # Value augmentation
                'degrees': 0.0,  # Sin rotaciÃ³n (minerÃ­a tiene orientaciÃ³n especÃ­fica)
                'translate': 0.1, # TranslaciÃ³n mÃ­nima
                'scale': 0.5,    # Escala moderada
                'shear': 0.0,    # Sin shear
                'perspective': 0.0, # Sin perspectiva
                'flipud': 0.0,   # Sin flip vertical
                'fliplr': 0.5,   # Flip horizontal OK
                'copy_paste': 0.0, # Sin copy-paste
                'auto_augment': 'randaugment', # AugmentaciÃ³n automÃ¡tica
                'erasing': 0.4,  # Random erasing probability
                'crop_fraction': 1.0, # Crop fraction
            }
            
            # Entrenar
            start_time = time.time()
            results = model.train(**train_args)
            training_time = time.time() - start_time
            
            # Evaluar en validation set
            val_results = model.val(data=str(yaml_path), verbose=False)
            
            # Extraer mÃ©tricas especÃ­ficas de la clase objetivo
            if hasattr(val_results, 'box') and val_results.box is not None:
                # MÃ©tricas por clase
                per_class_recall = val_results.box.r  # Recall por clase
                per_class_precision = val_results.box.p  # Precision por clase
                per_class_ap50 = val_results.box.ap50  # AP@0.5 por clase
                
                # MÃ©tricas de la clase objetivo (minerÃ­a ilegal)
                if len(per_class_recall) > self.target_class:
                    target_recall = per_class_recall[self.target_class]
                    target_precision = per_class_precision[self.target_class]
                    target_ap50 = per_class_ap50[self.target_class]
                else:
                    target_recall = target_precision = target_ap50 = 0.0
                
                # MÃ©tricas generales
                overall_map50 = val_results.box.map50
                overall_map = val_results.box.map
                
            else:
                target_recall = target_precision = target_ap50 = 0.0
                overall_map50 = overall_map = 0.0
            
            result = {
                'run_id': run_id,
                'config_name': config_name,
                'dataset': Path(dataset_path).name,
                'config': config,
                'target_class_recall': float(target_recall),
                'target_class_precision': float(target_precision),
                'target_class_ap50': float(target_ap50),
                'overall_map50': float(overall_map50),
                'overall_map': float(overall_map),
                'training_time_minutes': training_time / 60,
                'final_epoch': self.base_epochs,
                'model_path': str(Path("runs/detect") / run_name / "weights" / "best.pt"),
                'gpu_memory_estimated': estimated_memory
            }
            
            print(f"   âœ… {config_name}: Recall clase {self.target_class}: {target_recall:.4f}")
            print(f"   ğŸ“Š Precision: {target_precision:.4f}, mAP@50: {overall_map50:.4f}")
            print(f"   â±ï¸ Tiempo: {training_time/60:.1f} min, ğŸ’¾ GPU: {estimated_memory:.1f}GB")
            
            return result
            
        except Exception as e:
            print(f"   âŒ Error: {str(e)}")
            return {
                'run_id': run_id,
                'dataset': Path(dataset_path).name,
                'config': config,
                'error': str(e),
                'target_class_recall': 0.0
            }
        
        finally:
            # Limpiar memoria
            torch.cuda.empty_cache()

    def run_search(self):
        """Ejecuta la bÃºsqueda completa de hiperparÃ¡metros"""
        
        configurations = self.get_hyperparameter_combinations()
        total_runs = len(configurations) * len(self.dataset_paths)
        
        print(f"\nğŸ¯ INICIANDO BÃšSQUEDA DE HIPERPARÃMETROS")
        print(f"   Total de experimentos: {total_runs}")
        print(f"   Tiempo estimado: {total_runs * 15:.0f} minutos")
        print("="*60)
        
        run_id = 0
        all_results = []
        
        for dataset_path in self.dataset_paths:
            print(f"\nğŸ“ Dataset: {Path(dataset_path).name}")
            
            for config in configurations:
                run_id += 1
                result = self.train_single_config(config, dataset_path, run_id)
                
                if result:
                    all_results.append(result)
                    
                    # Guardar resultados parciales
                    self.save_partial_results(all_results)
                
                # Breve pausa para la GPU
                time.sleep(2)
        
        self.results = all_results
        self.analyze_and_save_results()
        
        return all_results

    def save_partial_results(self, results):
        """Guarda resultados parciales"""
        df = pd.DataFrame(results)
        df.to_csv(self.output_dir / "partial_results.csv", index=False)
        
        with open(self.output_dir / "partial_results.json", 'w') as f:
            json.dump(results, f, indent=2)

    def analyze_and_save_results(self):
        """Analiza y guarda los resultados finales"""
        
        df = pd.DataFrame(self.results)
        
        # Filtrar errores
        valid_results = df[df['target_class_recall'] > 0].copy()
        
        if len(valid_results) == 0:
            print("âŒ No hay resultados vÃ¡lidos")
            return
        
        # Ordenar por recall de clase objetivo
        valid_results = valid_results.sort_values('target_class_recall', ascending=False)
        
        print(f"\nğŸ† TOP 5 CONFIGURACIONES POR RECALL CLASE {self.target_class} (MINERÃA ILEGAL):")
        print("="*90)
        
        for i, (_, row) in enumerate(valid_results.head(5).iterrows()):
            config_name = row.get('config_name', f"Run {row['run_id']}")
            print(f"\nğŸ¥‡ #{i+1} - {config_name} ({row['dataset']})")
            print(f"   ğŸ¯ Recall MinerÃ­a: {row['target_class_recall']:.4f}")
            print(f"   ğŸ“Š Precision: {row['target_class_precision']:.4f}")
            print(f"   ğŸ“ˆ AP@50 MinerÃ­a: {row['target_class_ap50']:.4f}")
            print(f"   ğŸŒŸ mAP@50 General: {row['overall_map50']:.4f}")
            
            # Mostrar configuraciÃ³n clave
            if isinstance(row['config'], dict):
                config = row['config']
                print(f"   âš™ï¸ Config: Batch={config.get('batch_size', 'N/A')}, "
                      f"LR={config.get('lr0', 'N/A')}, "
                      f"Img={config.get('imgsz', 'N/A')}, "
                      f"Model={config.get('model_size', 'N/A')}")
                print(f"   ğŸ”§ Augment: Mosaic={config.get('mosaic', 'N/A')}, "
                      f"Mixup={config.get('mixup', 'N/A')}, "
                      f"Dropout={config.get('dropout', 'N/A')}")
            
            print(f"   ğŸ•’ Tiempo: {row['training_time_minutes']:.1f} min")
            print(f"   ğŸ’¾ GPU estimada: {row.get('gpu_memory_estimated', 'N/A')} GB")
        
        # AnÃ¡lisis especÃ­fico para minerÃ­a ilegal
        mining_recalls = valid_results['target_class_recall']
        print(f"\nğŸ“Š ESTADÃSTICAS DE RECALL PARA MINERÃA ILEGAL:")
        print(f"   ğŸ¯ Mejor recall: {mining_recalls.max():.4f}")
        print(f"   ğŸ“ˆ Recall promedio: {mining_recalls.mean():.4f}")
        print(f"   ğŸ“‰ Recall mÃ­nimo: {mining_recalls.min():.4f}")
        print(f"   ğŸª Configuraciones > 0.8 recall: {len(mining_recalls[mining_recalls > 0.8])}")
        print(f"   ğŸ”¥ Configuraciones > 0.9 recall: {len(mining_recalls[mining_recalls > 0.9])}")
        
        # AnÃ¡lisis por dataset
        print(f"\nğŸ“ ANÃLISIS POR DATASET:")
        for dataset in valid_results['dataset'].unique():
            subset = valid_results[valid_results['dataset'] == dataset]
            best_recall = subset['target_class_recall'].max()
            avg_recall = subset['target_class_recall'].mean()
            best_config = subset.loc[subset['target_class_recall'].idxmax(), 'config_name']
            
            print(f"   ğŸ“‚ {dataset}:")
            print(f"      ğŸ† Mejor: {best_recall:.4f} ({best_config})")
            print(f"      ğŸ“Š Promedio: {avg_recall:.4f}")
            print(f"      ğŸ§ª Experimentos: {len(subset)}")
        
        # Recomendaciones
        best_overall = valid_results.iloc[0]
        print(f"\nğŸ’¡ RECOMENDACIONES:")
        
        if best_overall['target_class_recall'] >= 0.9:
            print(f"   âœ… Â¡EXCELENTE! Recall de {best_overall['target_class_recall']:.4f} alcanzado")
            print(f"   ğŸš€ Usar configuraciÃ³n: {best_overall.get('config_name', 'N/A')}")
            print(f"   ğŸ“ Con dataset: {best_overall['dataset']}")
        elif best_overall['target_class_recall'] >= 0.8:
            print(f"   âœ… BUENO. Recall de {best_overall['target_class_recall']:.4f}")
            print(f"   ğŸ”§ Considera entrenamiento mÃ¡s largo (250+ Ã©pocas)")
            print(f"   ğŸ¯ O ajustar threshold de confianza en inferencia")
        else:
            print(f"   âš ï¸ Recall bajo: {best_overall['target_class_recall']:.4f}")
            print(f"   ğŸ”„ Considera mÃ¡s data augmentation")
            print(f"   ğŸ“ˆ O threshold de confianza mÃ¡s bajo (0.1-0.15)")
        
        
        print(f"\nâœ… Resultados guardados en: {self.output_dir}")

# FunciÃ³n de uso fÃ¡cil
def search_hyperparameters_for_recall():
    """FunciÃ³n principal para ejecutar la bÃºsqueda"""
    
    # Rutas de tus datasets
    datasets = [
    "preprocesamiento/modelo_yolov11_dataset_completo_preprocesado"
    ]
    
    # Crear y ejecutar bÃºsqueda
    searcher = HyperparameterSearchRecall(
        dataset_paths=datasets,
        target_class=4,  # Clase de minerÃ­a ilegal
        base_epochs=100,
        gpu_memory_gb=24
    )
    
    results = searcher.run_search()
    
    return searcher, results

# Ejecutar bÃºsqueda
if __name__ == "__main__":
    searcher, results = search_hyperparameters_for_recall()
    print("\nğŸ‰ BÃºsqueda completada!")